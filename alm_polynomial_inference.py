from functools import partial

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from emcee import EnsembleSampler
from chainconsumer import ChainConsumer
from numba import jit

import nregions_inference as NRI
import src.sky_models as SM
import src.forward_model as FM
from anstey.generate import T_CMB
from src.spherical_harmonics import RealSphericalHarmonics
RS = RealSphericalHarmonics()


def _alm_forward_model(nuarr, *c, a00_offset=False):
    """
    Calculate the alm polynomial given a vector of components c = (A/1000, alpha, *zetas)
    Note the rescaling on the A term.
    """
    A, alpha = c[:2]
    zetas    = c[2:]
    exponent = [zetas[i]*np.log(nuarr/60)**(i+2) for i in range(len(zetas))]
    alm_term = (A*1e3)*(nuarr/60)**(-alpha) * np.exp(np.sum(exponent, 0))
    if a00_offset:
        alm_term += np.sqrt(4*np.pi)*T_CMB
    return alm_term

def _regress_powerlaw(nuarr, alm, Npoly=2, a00_offset=False):
    """
    Assuming that alm = A(nu/60)^alpha exp(zeta_0 log(nuarr/60)^2 + zeta_1 log(nuarr/60)^3 + ...)
    find the vector of values c=(A, alpha, zeta_0, ...) up to Npoly total terms.

    This can deal with negative alm functions.
    """
    assert Npoly >= 2
    
    # Guess at the initial parameters
    if np.all(alm>0):
        p0 = [10, 2.5] + [0.001]*(Npoly-2)
    elif np.all(alm<0):
        p0 = [-10, 2.5] + [0.001]*(Npoly-2)
    else:
        return 0
    f = partial(_alm_forward_model, a00_offset=a00_offset)
    fit, cov = curve_fit(f, nuarr, alm, p0=p0)

    return fit, cov

def _fit_alms(nuarr, alm_list, Npoly=4):
    """
    Fit a list of alms from a00 upwards.
    """
    fitlist = []
    for i, alm in enumerate(alm_list):
        try:
            if i==0:
                a00_offset=True
            else:
                a00_offset=False
            fit, _ = _regress_powerlaw(nuarr, alm, Npoly=Npoly, a00_offset=a00_offset)
        except:
            print(f"Error: cannot fit {i} as it has a zero-crossing, skipping it for now.")
        fitlist.append(fit)
    return np.array(fitlist)


def compare_polyn_reconstructions(lmax, lmod, Npoly):
    """
    Compare data generated by observing a fiducial lmax model with data generated by 
    observing an lmod model, who's alm parameters are polynomial best-fits of
    the alms of the lmax model. The polynomial order to fit up to is controlled
    by Npoly.
    """
    # Generate data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.0
    Ntau=len(times)
    lats=[-26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = Ntau,
        lmax = lmax,
        lats = lats,
        nside = nside
    )
    if lmax != lmod:
        _, _, mat_A_mod, _, _ = NRI.fiducial_obs(
            uniform_noise=True,
            unoise_K = noise,
            times = times,
            Ntau = Ntau,
            lmax = lmod,
            lats = lats,
            nside = nside
        )
    else:
        mat_A_mod = mat_A
    derr = np.sqrt(np.diag(noise_covar.matrix))
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")


    # Fit the first lmod alms of the fiducial model.
    nuarr = NRI.nuarr
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmod, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))

    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)

    # Evaluating the model at the fiducial parameter set.
    mod = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A_mod, Npoly=Npoly, lmax=lmod)
    dmod = mod(fitlist.flatten())
    plt.plot(dmod, '.', label='fiducial model')
    plt.legend()
    plt.show()

    plt.errorbar(list(range(len(dnoisy.vector))),dnoisy.vector-dmod, yerr=derr,fmt='.')
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()


def compare_fm_reconstructions(lmax, lmod, Npoly, steps=3000, burn_in=1000):
    """
    Do the above by fitting the model (lmod) to the fiducial data generated by
    an lmax model in data space using MCMC.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.001
    lats  = [-26, 26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmax,
        nside = nside,
        lats=lats
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Instantiate the model.
    nuarr = NRI.nuarr
    mod   = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A, Npoly=Npoly, lmax=lmod)

    # "Cheat" to find the fiducial parameter set so we can start the inference there.
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmod, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))

    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    theta_guess = fitlist.flatten()
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)
    chain = sampler.get_chain(flat=True, discard=burn_in)

    # Plot chain.
    c = ChainConsumer()
    c.add_chain(chain)
    f = c.plotter.plot()
    plt.show()

    # Plot residuals to fit.
    theta_inferred = np.mean(chain, axis=0)
    d_inferred = mod(theta_inferred)
    plt.plot(dnoisy.vector-d_inferred, '.')
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()


def compare_fm_fidpl_reconstruction(lmax, lmod, Npoly, steps=3000, burn_in=1000):
    """
    Forward-model fit the first lmod alms of the foreground polynomial model, 
    and take the rest of the alms to be power law approximations to the
    fiducial values.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.01
    lats  = [-26, 26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmax,
        nside = nside,
        lats=lats
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Instantiate the model.
    nuarr   = NRI.nuarr
    fullmod = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A, Npoly=Npoly, lmax=lmax)  # used to be lmod

    # Compute the 0<l<lmod alm polynomial parameters as an initial guess for the
    # inference, and the lmod<l<lmax polynomial parameters to evaluate the model
    # at these automatically.
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmax, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))
    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)
    Nlmod = RS.get_size(lmax=lmod)
    fit_parguess = fitlist[:Nlmod]
    fit_fidpars  = fitlist[Nlmod:]
    theta_guess = fit_parguess.flatten()
    theta_fid   = fit_fidpars.flatten()

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # Partially evaluate the model.
    @jit
    def mod(theta):
        all_theta = np.zeros(len(theta_fid)+len(theta_guess))
        all_theta[:len(theta_guess)] = theta
        all_theta[len(theta_guess):] = theta_fid
        return fullmod(all_theta)

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)
    chain = sampler.get_chain(flat=True, discard=burn_in)

    # Plot chain.
    c = ChainConsumer()
    c.add_chain(chain)
    f = c.plotter.plot()
    plt.show()

    # Plot residuals to fit.
    theta_inferred = np.mean(chain, axis=0)
    d_inferred = mod(theta_inferred)
    plt.errorbar(range(len(dnoisy.vector)), dnoisy.vector-d_inferred, '.')
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()


# Important function: fiducial foreground correction with exact values.
def compare_fm_fid_reconstruction(lmax, lmod, Npoly, steps=3000, burn_in=1000):
    """
    Forward-model fit the first lmod alms of the foreground polynomial model, 
    and take the rest of the alms to be the fiducial values.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.01
    lats  = [-26, 26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmax,
        nside = nside,
        lats=lats
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Compute the 0<l<lmod alm polynomial parameters as an initial guess for the
    # inference, and store the lmod<l<lmax alms to use as the fiducial correction.
    nuarr = NRI.nuarr
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmax, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))
    Nlmod = RS.get_size(lmax=lmod)
    alms_for_guess = a_sep.T[:Nlmod]
    alms_for_corr  = a_sep.T[Nlmod:]
    fitlist=_fit_alms(nuarr=nuarr, alm_list=alms_for_guess, Npoly=Npoly)
    theta_guess = fitlist.flatten()

    # Instantiate the model.
    mod   = FM.genopt_alm_plfid_forward_model(nuarr, observation_mat=mat_A, fid_alm=alms_for_corr, Npoly=Npoly, lmod=lmod, lmax=lmax)

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)
    chain = sampler.get_chain(flat=True, discard=burn_in)

    # Plot chain.
    c = ChainConsumer()
    c.add_chain(chain)
    f = c.plotter.plot()
    plt.show()

    # Plot residuals to fit.
    theta_inferred = np.mean(chain, axis=0)
    d_inferred = mod(theta_inferred)
    plt.errorbar(range(len(dnoisy.vector)), dnoisy.vector-d_inferred, err, fmt='.')
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()

