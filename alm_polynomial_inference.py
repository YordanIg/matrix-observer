from functools import partial
import pickle

import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
from emcee import EnsembleSampler
from chainconsumer import ChainConsumer
from numba import jit

import nregions_inference as NRI
import src.inference as INF
import src.observing as OBS
import src.sky_models as SM
import src.forward_model as FM
import src.beam_functions as BF
from src.blockmat import BlockMatrix, BlockVector
from anstey.generate import T_CMB
from src.spherical_harmonics import RealSphericalHarmonics
RS = RealSphericalHarmonics()


def _alm_forward_model(nuarr, *c, a00_offset=False):
    """
    Calculate the alm polynomial given a vector of components c = (A/1000, alpha, *zetas)
    Note the rescaling on the A term.
    """
    A, alpha = c[:2]
    zetas    = c[2:]
    exponent = [zetas[i]*np.log(nuarr/60)**(i+2) for i in range(len(zetas))]
    alm_term = (A*1e3)*(nuarr/60)**(-alpha) * np.exp(np.sum(exponent, 0))
    if a00_offset:
        alm_term += np.sqrt(4*np.pi)*T_CMB
    return alm_term

def _regress_powerlaw(nuarr, alm, Npoly=2, a00_offset=False):
    """
    Assuming that alm = A(nu/60)^alpha exp(zeta_0 log(nuarr/60)^2 + zeta_1 log(nuarr/60)^3 + ...)
    find the vector of values c=(A, alpha, zeta_0, ...) up to Npoly total terms.

    This can deal with negative alm functions.
    """
    assert Npoly >= 2
    
    # Guess at the initial parameters
    if np.all(alm>0):
        p0 = [10, 2.5] + [0.001]*(Npoly-2)
    elif np.all(alm<0):
        p0 = [-10, 2.5] + [0.001]*(Npoly-2)
    else:
        return 0
    f = partial(_alm_forward_model, a00_offset=a00_offset)
    fit, cov = curve_fit(f, nuarr, alm, p0=p0)

    return fit, cov

def _fit_alms(nuarr, alm_list, Npoly=4):
    """
    Fit a list of alms from a00 upwards.
    """
    fitlist = []
    for i, alm in enumerate(alm_list):
        try:
            if i==0:
                a00_offset=True
            else:
                a00_offset=False
            fit, _ = _regress_powerlaw(nuarr, alm, Npoly=Npoly, a00_offset=a00_offset)
        except:
            print(f"Error: cannot fit {i} as it has a zero-crossing, skipping it for now.")
        fitlist.append(fit)
    return np.array(fitlist)


def compare_polyn_reconstructions(lmax, lmod, Npoly):
    """
    Compare data generated by observing a fiducial lmax model with data generated by 
    observing an lmod model, who's alm parameters are polynomial best-fits of
    the alms of the lmax model. The polynomial order to fit up to is controlled
    by Npoly.
    """
    # Generate data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.0
    Ntau=len(times)
    lats=[-26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = Ntau,
        lmax = lmax,
        lats = lats,
        nside = nside
    )
    if lmax != lmod:
        _, _, mat_A_mod, _, _ = NRI.fiducial_obs(
            uniform_noise=True,
            unoise_K = noise,
            times = times,
            Ntau = Ntau,
            lmax = lmod,
            lats = lats,
            nside = nside
        )
    else:
        mat_A_mod = mat_A
    derr = np.sqrt(np.diag(noise_covar.matrix))
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")


    # Fit the first lmod alms of the fiducial model.
    nuarr = NRI.nuarr
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmod, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))

    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)

    # Evaluating the model at the fiducial parameter set.
    mod = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A_mod, Npoly=Npoly, lmax=lmod)
    dmod = mod(fitlist.flatten())
    plt.plot(dmod, '.', label='fiducial model')
    plt.legend()
    plt.show()

    plt.errorbar(list(range(len(dnoisy.vector))),dnoisy.vector-dmod, yerr=derr,fmt='.')
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()


def compare_fm_reconstructions(lmax, lmod, Npoly, steps=3000, burn_in=1000, savetag=None):
    """
    Do the above by fitting the model (lmod) to the fiducial data generated by
    an lmax model in data space using MCMC.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.001
    lats  = [-26, 26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmax,
        nside = nside,
        lats=lats
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Instantiate the model.
    _, _, mat_A_mod, _, _ = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmod,
        nside = nside,
        lats = [-26, 26]
    )
    nuarr = NRI.nuarr
    mod   = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A_mod, Npoly=Npoly, lmax=lmod)

    # "Cheat" to find the fiducial parameter set so we can start the inference there.
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmod, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))

    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    theta_guess = fitlist.flatten()
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)

    if savetag is None:
        chain = sampler.get_chain(flat=True, discard=burn_in)
        _plot_inference(chain, dnoisy.vector, mod)
    else:
        print(f"SAVING CHAIN AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
        print(f"SAVING DATA AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
        if burn_in is not None:
            print("WARNING: ignoring burn-in value")
        chain = sampler.get_chain()
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy", chain)
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy", dnoisy.vector)


def compare_fm_fidpl_reconstruction(lmax, lmod, Npoly, steps=3000, burn_in=1000, savetag=None):
    """
    Forward-model fit the first lmod alms of the foreground polynomial model, 
    and take the rest of the alms to be power law approximations to the
    fiducial values.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.01
    lats  = [-26, 26]
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = len(times),
        lmax = lmax,
        nside = nside,
        lats=lats
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Instantiate the model.
    nuarr   = NRI.nuarr
    fullmod = FM.genopt_alm_pl_forward_model(nuarr, observation_mat=mat_A, Npoly=Npoly, lmax=lmax)  # used to be lmod

    # Compute the 0<l<lmod alm polynomial parameters as an initial guess for the
    # inference, and the lmod<l<lmax polynomial parameters to evaluate the model
    # at these automatically.
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmax, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))
    fitlist=_fit_alms(nuarr=nuarr, alm_list=a_sep.T, Npoly=Npoly)
    Nlmod = RS.get_size(lmax=lmod)
    fit_parguess = fitlist[:Nlmod]
    fit_fidpars  = fitlist[Nlmod:]
    theta_guess = fit_parguess.flatten()
    theta_fid   = fit_fidpars.flatten()

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # Partially evaluate the model.
    @jit
    def mod(theta):
        all_theta = np.zeros(len(theta_fid)+len(theta_guess))
        all_theta[:len(theta_guess)] = theta
        all_theta[len(theta_guess):] = theta_fid
        return fullmod(all_theta)

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)

    if savetag is None:
        chain = sampler.get_chain(flat=True, discard=burn_in)
        _plot_inference(chain, dnoisy.vector, mod)
    else:
        print(f"SAVING CHAIN AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
        print(f"SAVING DATA AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
        if burn_in is not None:
            print("WARNING: ignoring burn-in value")
        chain = sampler.get_chain()
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy", chain)
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy", dnoisy.vector)


# Important function: fiducial foreground correction with exact values.
def compare_fm_fid_reconstruction(lmax, lmod, Npoly, steps=3000, burn_in=1000, savetag=None):
    """
    Forward-model fit the first lmod alms of the foreground polynomial model, 
    and take the rest of the alms to be the fiducial values.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 6, 3)
    noise = 0.01#2e-5
    lats  = [-26]
    Ntau  = 1
    dnoisy, noise_covar, mat_A, mat_Y, params = NRI.fiducial_obs(
        uniform_noise=True,
        unoise_K = noise,
        times = times,
        Ntau = Ntau,
        lmax = lmax,
        nside = nside,
        lats=lats,
        delta=1e-1,
        chrom=True
    )
    plt.plot(dnoisy.vector, '.', label='mock data')
    plt.xlabel("bin")
    plt.ylabel("Temp [K]")
    plt.show()

    # Compute the 0<l<lmod alm polynomial parameters as an initial guess for the
    # inference, and store the lmod<l<lmax alms to use as the fiducial correction.
    nuarr = NRI.nuarr
    a = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmax, nside=nside, use_mat_Y=True)
    a_sep = np.array(np.split(a, len(nuarr)))
    Nlmod = RS.get_size(lmax=lmod)
    alms_for_guess = a_sep.T[:Nlmod]
    alms_for_corr  = a_sep.T[Nlmod:]
    fitlist=_fit_alms(nuarr=nuarr, alm_list=alms_for_guess, Npoly=Npoly)
    theta_guess = fitlist.flatten()

    # Instantiate the model.
    mod = FM.genopt_alm_plfid_forward_model(nuarr, observation_mat=mat_A, fid_alm=alms_for_corr, Npoly=Npoly, lmod=lmod, lmax=lmax)

    # create a small ball around the MLE the initialize each walker
    nwalkers, fg_dim = 64, Npoly*RS.get_size(lmod)
    ndim = fg_dim
    pos = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))

    # run emcee without priors
    err = np.sqrt(noise_covar.diag)
    sampler = EnsembleSampler(nwalkers, ndim, NRI.log_likelihood, 
                        args=(dnoisy.vector, err, mod))
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)

    if savetag is None:
        chain = sampler.get_chain(flat=True, discard=burn_in)
        _plot_inference(chain, dnoisy.vector, mod, err)
    else:
        print(f"SAVING CHAIN AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
        print(f"SAVING DATA AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
        if burn_in is not None:
            print("WARNING: ignoring burn-in value")
        chain = sampler.get_chain()
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy", chain)
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy", dnoisy.vector)
    del mat_A


def compare_fm_fid_reconstruction_with21cm(lmax, lmod, Npoly, lats=None, steps=3000, burn_in=1000, savetag=None, basemap_err=5, chrom=None):
    """
    Forward-model fit the first lmod alms of the foreground polynomial model and
    the Gaussian 21-cm monopole,
    and take the rest of the alms to be the fiducial values.
    """
    # Generate the data.
    nside = 32
    times = np.linspace(0, 24, 24, endpoint=False)
    if lats is None:
        lats = np.array([-26*3, -26*2, -26, 0, 26, 26*2, 26*3])
    Ntau  = len(times)
    cm21_mon_pars = OBS.cm21_params
    delta = SM.basemap_err_to_delta(percent_err=basemap_err, ref_freq=70)

    dnoisy, noise_covar, mat_A, mat_Y, params = OBS.fiducial_obs(
        uniform_noise=False,
        tint = 200,
        times = times,
        Ntau = Ntau,
        lmax = lmax,
        nside = nside,
        lats=lats,
        cm21_pars=cm21_mon_pars,
        delta=delta,
        chrom=chrom
    )
    err = np.sqrt(noise_covar.diag)

    # Compute the 0<l<lmod alm polynomial parameters as an initial guess for the
    # inference, and store the lmod<l<lmax alms to use as the fiducial correction.
    nuarr          = NRI.nuarr
    a              = SM.foreground_gsma_alm_nsidelo(nu=nuarr, lmax=lmax, nside=nside, use_mat_Y=True, delta=delta)
    a_sep          = np.array(np.split(a, len(nuarr)))
    Nlmod          = RS.get_size(lmax=lmod)
    Nlmax          = RS.get_size(lmax=lmax)
    alms_for_guess = a_sep.T[:Nlmod]
    fitlist        =_fit_alms(nuarr=nuarr, alm_list=alms_for_guess, Npoly=Npoly)
    theta_guess    = fitlist.flatten()
    print(fitlist.flatten())

    # Generate a missing-modes correction analytically.
    mat_A_mod         = mat_A[:,:Nlmod]
    mat_A_unmod       = BlockMatrix(mat_A.block[:,:,Nlmod:])
    alm_mean, alm_cov = SM.gsma_corr(lmod, lmax, nside, nuarr, basemap_err, ref_freq=70)
    covar_corr        = mat_A_unmod @ alm_cov @ mat_A_unmod.T

    # Compute the correction.
    total_inv_cov     = (noise_covar + covar_corr).inv
    total_inv_cov_np  = total_inv_cov.matrix
    dnoisy_corr       = dnoisy - mat_A_unmod @ alm_mean

    # Instantiate the models.
    mod_fg = FM.genopt_alm_plfid_forward_model(
        nuarr, 
        observation_mat=mat_A_mod,
        Npoly=Npoly, 
        lmod=lmod, 
        lmax=lmax
    )
    mod = FM.genopt_alm_plfid_forward_model_with21cm(
        nuarr, 
        observation_mat=mat_A_mod,
        Npoly=Npoly, 
        lmod=lmod, 
        lmax=lmax
    )
    priors = [[-10, 25], [1.5, 3.5]]
    priors += [[-100, 100.1]]*(Npoly-2)
    priors = priors*Nlmod
    bounds = [list(x) for x in zip(*priors)]
    
    # First run curve_fit to generate a better starting guess (if basemap errs 
    # are included)
    if chrom is not None and chrom is not False and lmod==0:
        try:
            def mod_cf(nuarr, *theta):
                theta = np.array(theta)
                return mod_fg(theta)
            res = curve_fit(mod_cf, nuarr, dnoisy_corr.vector, p0=theta_guess, method="dogbox", bounds=bounds)
            theta_guess = res[0]
        except RuntimeError:
            print("failed to estimate optimal parameters using curve_fit")
    
    # Add the 21-cm parameters to theta_guess.
    theta_guess = np.append(theta_guess, cm21_mon_pars)
    priors      = [[-10, 25], [1.5, 3.5]]
    priors     += [[-100, 100]]*(Npoly-2)
    priors      = priors*Nlmod
    priors     += [[-0.5, -0.01], [60, 90], [5, 15]]
    priors      = np.array(priors)
    theta_guess = INF.prior_checker(priors, theta_guess)
    

    nwalkers, fg_dim = 64, Npoly*Nlmod
    ndim             = fg_dim + len(cm21_mon_pars)
    pos              = theta_guess*(1 + 1e-4*np.random.randn(nwalkers, ndim))
    sampler = EnsembleSampler(
        nwalkers, 
        ndim, 
        INF.log_posterior_vectors, 
        args=(dnoisy.vector, total_inv_cov_np, mod, priors)
    )
    _=sampler.run_mcmc(pos, nsteps=steps, progress=True)

    if savetag is None:
        chain = sampler.get_chain(flat=True, discard=burn_in)
        _plot_inference(chain, dnoisy_corr.vector, mod, err)
    else:
        print(f"SAVING CHAIN AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
        print(f"SAVING DATA AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
        print(f"SAVING ERRORS AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_errs.npy")
        print(f"SAVING PARAMS AS lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_pars.pkl")
        if burn_in is not None:
            print("WARNING: ignoring burn-in value")
        chain = sampler.get_chain()

        pars = {
            "nuarr" : nuarr,
            "nside" : nside,
            "Ntau"  : Ntau,
            "lats"  : lats,
            "times" : times,
            "chrom" : chrom,
            "delta" : delta
        }
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy", chain)
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy", dnoisy_corr.vector)
        np.save(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_errs.npy", np.sqrt(noise_covar.diag))
        with open(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_pars.pkl", 'wb') as f:
            pickle.dump(pars, f)
    del mat_A


def _plot_inference(chain, dnoisy_vector, model, errors):
    c = ChainConsumer()
    c.add_chain(chain)
    f = c.plotter.plot()
    plt.show()

    # Plot residuals to fit.
    theta_inferred = np.mean(chain, axis=0)
    d_inferred = model(theta_inferred)
    residuals = dnoisy_vector - d_inferred
    if errors is None:
        plt.plot(residuals, '.')
    else:
        plt.errorbar(np.linspace(50,100,51), residuals, errors, fmt='.')
        # Compute chi-square.
        chi_sq = np.sum(residuals**2/errors)
        print(f"Reduced chi square = {chi_sq/(len(dnoisy_vector)-(len(chain[0])))}")
    plt.xlabel("bin")
    plt.ylabel("Temp residuals [K]")
    plt.show()

def plot_corner(lmax, lmod, Npoly, savetag, burn_in=1000):
    """
    Plotting code for MCMC chains generated by the function
    compare_fm_fid_reconstruction_with21cm to display just the corner plot.
    """
    print(f"loading saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
    chain = np.load(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
    chain = chain[burn_in:]
    nwalkers, nsteps, ndim = np.shape(chain)
    chain_flat = np.reshape(chain, (nwalkers*nsteps, ndim))

    c = ChainConsumer()
    c.add_chain(chain_flat)
    f = c.plotter.plot()
    plt.show()

def plot_chain_with21cm(lmax, lmod, Npoly, savetag, burn_in=1000, plot_residuals=False):
    """
    Plotting code for MCMC chains generated by the function
    compare_fm_fid_reconstruction_with21cm.
    """
    print(f"loading saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
    print(f"loading saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
    print(f"loading saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_errs.npy")
    chain = np.load(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_chain.npy")
    data  = np.load(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_data.npy")
    errs  = np.load(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_errs.npy")

    # Reshape and burn in the chain.
    chain = chain[burn_in:]
    nwalkers, nsteps, ndim = np.shape(chain)
    chain_flat = np.reshape(chain, (nwalkers*nsteps, ndim))

    # Now plot the results in data space. Need to re-initialise the original
    # model.
    with open(f"saves/Alm_corrected/lmax{lmax}_lmod{lmod}_Npoly{Npoly}_{savetag}_pars.pkl", 'rb') as f:
        pars = pickle.load(f)
        print(f"model pars are {pars}")
        
    # Compute the observation matrix.
    narrow_cosbeam = lambda x: BF.beam_cos(x, 0.8)
    if isinstance(pars['chrom'], bool):
        if not pars['chrom']:
            mat_A = FM.calc_observation_matrix_multi_zenith_driftscan_multifreq(nuarr=pars['nuarr'], nside=pars['nside'], lmax=lmax, Ntau=pars['Ntau'], lats=pars['lats'], times=pars['times'], beam_use=narrow_cosbeam)
        elif pars['chrom']:
            mat_A = FM.calc_observation_matrix_multi_zenith_driftscan_chromatic(pars['nuarr'], pars['nside'], lmax, pars['Ntau'], pars['lats'], pars['times'], beam_use=BF.beam_cos_FWHM, chromaticity=BF.fwhm_func_tauscher)
    elif pars['chrom'] is None:
        mat_A = FM.calc_observation_matrix_multi_zenith_driftscan_multifreq(nuarr=pars['nuarr'], nside=pars['nside'], lmax=lmax, Ntau=pars['Ntau'], lats=pars['lats'], times=pars['times'], beam_use=narrow_cosbeam)
    else:
        chromfunc = partial(BF.fwhm_func_tauscher, c=pars['chrom'])
        mat_A = FM.calc_observation_matrix_multi_zenith_driftscan_chromatic(pars['nuarr'], pars['nside'], lmax, pars['Ntau'], pars['lats'], pars['times'], beam_use=BF.beam_cos_FWHM, chromaticity=chromfunc)

    # Compute the correction alms.
    a = SM.foreground_gsma_alm_nsidelo(nu=pars['nuarr'], lmax=lmax, nside=pars['nside'], use_mat_Y=True)
    a_sep = np.array(np.split(a, len(pars['nuarr'])))
    Nlmod = RS.get_size(lmax=lmod)
    mat_A_mod = mat_A[:,:Nlmod]

    mod = FM.genopt_alm_plfid_forward_model_with21cm(pars['nuarr'], observation_mat=mat_A_mod, Npoly=Npoly, lmod=lmod, lmax=lmax)

    if plot_residuals:
        _plot_inference(chain=chain_flat, dnoisy_vector=data, model=mod, errors=errs)
    
    # Plot the 21-cm signal.
    chain_sample_indx = np.random.choice(len(chain_flat), 1000)
    chain_samples = chain_flat[chain_sample_indx]
    chain_samples_cm21 = chain_samples[:,-3:]
    cm21_temps = [FM.cm21_globalT(pars['nuarr'], *theta) for theta in chain_samples_cm21]
    cm21_temps_mean = np.mean(cm21_temps, axis=0)
    cm21_temps_std = np.std(cm21_temps, axis=0)

    plt.plot(pars['nuarr'], FM.cm21_globalT(pars['nuarr'], *OBS.cm21_params), label='fiducial', linestyle=':', color='k')
    plt.fill_between(
        pars['nuarr'],
        cm21_temps_mean-cm21_temps_std, 
        cm21_temps_mean+cm21_temps_std,
        color='C1',
        alpha=0.8,
        edgecolor='none',
        label="inferred"
    )
    plt.fill_between(
        pars['nuarr'],
        cm21_temps_mean-2*cm21_temps_std, 
        cm21_temps_mean+2*cm21_temps_std,
        color='C1',
        alpha=0.4,
        edgecolor='none'
    )
    plt.xlabel("Frequency [MHz]")
    plt.ylabel("21-cm monopole temperature [K]")
    plt.legend()
    plt.show()


if __name__=="__main__":
    Npoly_list = [6, 7, 8]
    chrom_list = [1.6e-2, 3.4e-2]

    for Npoly in Npoly_list:
        for chrom in chrom_list:
            if chrom == 1.6e-2:
                chromlab = '1'
            elif chrom == 3.4e-2:
                chromlab = '3'
            compare_fm_fid_reconstruction_with21cm(lmax=32, lmod=0, Npoly=Npoly, steps=5000, savetag=f"chrom{chromlab}_bmerr{5}", basemap_err=5, chrom=chrom)
